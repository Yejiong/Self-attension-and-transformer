{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4a5057",
   "metadata": {},
   "source": [
    "# Task description\n",
    "- Classify the speakers of given features.\n",
    "- Baselines:\n",
    "  - Easy: Run sample code and know how to use transformer.\n",
    "  - Medium: Know how to adjust parameters of transformer.\n",
    "  - Strong: Construct [conformer](https://arxiv.org/abs/2005.08100) which is a variety of transformer. \n",
    "  - Boss: Implement [Self-Attention Pooling](https://arxiv.org/pdf/2008.01077v1.pdf) & [Additive Margin Softmax](https://arxiv.org/pdf/1801.05599.pdf) to further boost the performance.\n",
    "\n",
    "\n",
    "# Download dataset\n",
    "- Data is [here](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5907d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anacoda\\envs\\Pytorch_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import module\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# seed setting\n",
    "def same_seeds(seed):\n",
    "    # Python built-in random module\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(1212)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19a4e4",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Dataset\n",
    "- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n",
    "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n",
    "- We randomly select 600 speakers from Voxceleb2.\n",
    "- Then preprocess the raw waveforms into mel-spectrograms.\n",
    "\n",
    "- Args:\n",
    "  - data_dir: The path to the data directory.\n",
    "  - metadata_path: The path to the metadata.\n",
    "  - segment_len: The length of audio segment for training. \n",
    "- The architecture of data directory \\\\\n",
    "  - data directory \\\\\n",
    "  |---- metadata.json \\\\\n",
    "  |---- testdata.json \\\\\n",
    "  |---- mapping.json \\\\\n",
    "  |---- uttr-{random string}.pt \\\\\n",
    "\n",
    "- The information in metadata\n",
    "  - \"n_mels\": The dimention of mel-spectrogram.\n",
    "  - \"speakers\": A dictionary. \n",
    "    - Key: speaker ids.\n",
    "    - value: \"feature_path\" and \"mel_len\"\n",
    "\n",
    "\n",
    "For efficiency, we segment the mel-spectrograms into segments in the traing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82cc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "## Create my dataset\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, data_dir, segment_length=128):\n",
    "        self.data_dir = data_dir\n",
    "        self.segment_length = segment_length\n",
    "    \n",
    "        # Load the mapping from speaker name to their corresponding id. \n",
    "        mapping_path = os.path.join(data_dir, 'mapping.json')\n",
    "        self.speaker2id = json.load(open(mapping_path))['speaker2id']\n",
    "        \n",
    "        # Load metadata of training data.\n",
    "        metadata_path = os.path.join(data_dir, 'metadata.json')\n",
    "        metadata = json.load(open(metadata_path))['speakers']\n",
    "        \n",
    "        # Get the total number of speaker\n",
    "        self.speaker_num = len(metadata)\n",
    "        self.data = []\n",
    "        for speaker in metadata.keys():\n",
    "            for voice in metadata[speaker]:\n",
    "                self.data.append([voice['feature_path'], self.speaker2id[speaker]])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath, speaker = self.data[idx]\n",
    "        # Load preprocessed mel-spectrogram.\n",
    "        mel = torch.load(os.path.join(self.data_dir, fpath))\n",
    "        \n",
    "        # Segmemt mel-spectrogram into \"segment_len\" frames.\n",
    "        if len(mel) > self.segment_length:\n",
    "            # Randomly get the starting point of the segment.\n",
    "            start = random.randint(0, len(mel) - self.segment_length)\n",
    "            # Get a segment with \"segment_len\" frames.\n",
    "            mel = torch.Tensor(mel[start:(start+self.segment_length)])\n",
    "        else:\n",
    "            mel = torch.Tensor(mel)\n",
    "        # Turn the speaker id into long for computing loss later.\n",
    "        speaker = torch.tensor(speaker)\n",
    "        return mel, speaker\n",
    "    \n",
    "    def get_speaker_num(self):\n",
    "        return self.speaker_num\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d88f7",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
    "- Create dataloader to iterate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74bde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    # Process features within a batch.\n",
    "    \"\"\"Collate a batch of data.\"\"\"\n",
    "    mel, speaker = list(zip(*batch))\n",
    "    # Because we train the model batch by batch, we need to pad \n",
    "    # the features in the same batch to make their lengths the same.\n",
    "    \n",
    "    mel = pad_sequence(mel, batch_first = True, padding_value = -20)\n",
    "    return mel, torch.Tensor(speaker).long()\n",
    "\n",
    "\n",
    "def get_dataloader(data_dir, batch_size):\n",
    "    \"\"\"\n",
    "    Generate dataloader\n",
    "    \"\"\"\n",
    "    dataset = Mydataset(data_dir)\n",
    "    speaker_num = dataset.get_speaker_num()\n",
    "    # Split dataset into training dataset and validation dataset\n",
    "    train_size = int(0.9*len(dataset))\n",
    "    valid_size = len(dataset) - train_size\n",
    "    trainset, validset = random_split(dataset, lengths=[train_size, valid_size])\n",
    "    \n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                              drop_last=True, pin_memory=True, \n",
    "                              collate_fn=collate_batch)\n",
    "    \n",
    "    valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=True,\n",
    "                              drop_last=True, pin_memory=True, \n",
    "                              collate_fn=collate_batch)\n",
    "    \n",
    "    return train_loader, valid_loader, speaker_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b6b75",
   "metadata": {},
   "source": [
    "# Model\n",
    "- TransformerEncoderLayer:\n",
    "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "  - Parameters:\n",
    "    - d_model: the number of expected features of the input (required).\n",
    "\n",
    "    - nhead: the number of heads of the multiheadattention models (required).\n",
    "\n",
    "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
    "\n",
    "    - dropout: the dropout value (default=0.1).\n",
    "\n",
    "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
    "\n",
    "- TransformerEncoder:\n",
    "  - TransformerEncoder is a stack of N transformer encoder layers\n",
    "  - Parameters:\n",
    "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "\n",
    "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "\n",
    "    - norm: the layer normalization component (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff64a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline model\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.prenet = nn.Linear(40, d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, batch_first=True, \n",
    "                                                        dim_feedforward=256, nhead=4, \n",
    "                                                        norm_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "        \n",
    "        self.pred_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, n_spks)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, length, 40)\n",
    "        out: (batch, size, n_spks)\n",
    "        \"\"\"\n",
    "        y = self.prenet(x)\n",
    "        y = self.encoder(y)\n",
    "        # mean pooling\n",
    "        y = y.mean(dim = 1)\n",
    "        y = self.pred_layer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77851025",
   "metadata": {},
   "source": [
    "### Build the [conformer](https://arxiv.org/abs/2005.08100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d2966f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Feedforward Module\n",
    "class Feedforwardmodule(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout_p=0.2, expansion_factor=2):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, embedding_dim * expansion_factor),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(embedding_dim * expansion_factor, embedding_dim),\n",
    "            nn.Dropout(dropout_p)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.layer(x)\n",
    "        return x + y\n",
    "\n",
    "## Multi-head self-attention module\n",
    "class MHST(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        \n",
    "        self.Mulithead = nn.MultiheadAttention(embedding_dim, num_heads=num_heads,\n",
    "                                               batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        self.Q_layer = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.K_layer = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.V_layer = nn.Linear(embedding_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.layer_norm(inputs)\n",
    "        Q = self.Q_layer(x)\n",
    "        K = self.K_layer(x)\n",
    "        V = self.V_layer(x)\n",
    "        y, x_weight = self.Mulithead(Q,K,V)\n",
    "        y = self.dropout(y)\n",
    "        \n",
    "        return inputs + y\n",
    "\n",
    "    \n",
    "## Convolution module\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, dim0, dim1):\n",
    "        super().__init__()\n",
    "        self.dim0 = dim0\n",
    "        self.dim1 = dim1\n",
    "    def forward(self, x):\n",
    "        return x.transpose(self.dim0, self.dim1)\n",
    "\n",
    "class ConvolutionModule(nn.Module):\n",
    "    \"\"\"\n",
    "    input shape: (B, L, in_channels)\n",
    "    \"\"\"  \n",
    "    def __init__(self, in_channels, kernal_size=3, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.LayerNorm(in_channels), ## shape: (B, L, in_channels)\n",
    "            Transpose(1,2), ## shape: (B, in_channels, L),\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=in_channels*2,\n",
    "                      kernel_size=1), ## shape: (B, 2*in_channels, L)\n",
    "            nn.GLU(dim=1), ## shape: (B, in_channels, L)\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=in_channels,\n",
    "                      kernel_size=kernal_size, groups=in_channels,padding=1),## shape : (B, out_channels, L)\n",
    "            nn.BatchNorm1d(in_channels), ## shape: (B, out_channels, L)\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(in_channels=in_channels,out_channels=in_channels, kernel_size=1),\n",
    "            nn.Dropout(p=dropout_p)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layer(x)\n",
    "        y = y.transpose(1,2)\n",
    "        return x+y\n",
    "    \n",
    "        \n",
    "\n",
    "## Conformer layer    \n",
    "class Conformer(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.FFL1 = Feedforwardmodule(embedding_dim=embedding_dim)\n",
    "        self.mhst = MHST(embedding_dim=embedding_dim, num_heads = 5)\n",
    "        self.convolution = ConvolutionModule(in_channels = embedding_dim)\n",
    "        self.FFL2 = Feedforwardmodule(embedding_dim=embedding_dim)\n",
    "        self.layernorm = nn.LayerNorm(embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y1 = 0.5*self.FFL1(x) + x\n",
    "        y2 = self.mhst(y1) +y1\n",
    "        y3 = self.convolution(y2) + y2\n",
    "        y4 = 0.5*self.FFL2(y3) + y3\n",
    "        output = self.layernorm(y4)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "## conformer encode model\n",
    "\n",
    "class ConformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conformers = nn.ModuleList([Conformer(embedding_dim=80) for i in range(6)])\n",
    "        self.prenet = nn.Sequential(\n",
    "            nn.Linear(40, d_model),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        self.pred_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, n_spks)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.prenet(x)\n",
    "        \n",
    "        for layer in self.conformers:\n",
    "            x1 = layer(x1)\n",
    "        \n",
    "        x2 = x1.mean(dim=1)\n",
    "        output = self.pred_layer(x2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "843d8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 600])\n",
      "764920\n"
     ]
    }
   ],
   "source": [
    "conformer_model = ConformerEncoder()\n",
    "x = torch.randn(32, 108, 40)\n",
    "y = conformer_model(x)\n",
    "print(y.shape)\n",
    "\n",
    "num_pars = 0\n",
    "for par in conformer_model.parameters():\n",
    "    num_pars += par.numel()\n",
    "print(num_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c147dd5",
   "metadata": {},
   "source": [
    "## Learning rate schedule\n",
    "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
    "-The warmup of learning rate is useful for training models with transformer architectures.\n",
    "- The warmup schedule\n",
    "  - Set learning rate to 0 in the beginning.\n",
    "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d83f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "def lr_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps,\n",
    "                            num_cycles=0.5, last_epoch=-1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a schedule with a learning rate that decreases following the values \n",
    "    of the cosine function between the initial lr set in the optimizer to 0, \n",
    "    after a warmup period during which it increases linearly between 0 and the\n",
    "    initial lr set in the optimizer.\n",
    "\n",
    "    Args:\n",
    "        optimizer (:class:`~torch.optim.Optimizer`):\n",
    "        The optimizer for which to schedule the learning rate.\n",
    "        num_warmup_steps (:obj:`int`):\n",
    "        The number of steps for the warmup phase.\n",
    "        num_training_steps (:obj:`int`):\n",
    "        The total number of training steps.\n",
    "        num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
    "        The number of waves in the cosine schedule \n",
    "        (the defaults is to just decrease from the max value to 0\n",
    "        following a half-cosine).\n",
    "        last_epoch (:obj:`int`, `optional`, defaults to -1):\n",
    "        The index of the last epoch when resuming training.\n",
    "\n",
    "    Return:\n",
    "        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "    \"\"\"  \n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        # warm up\n",
    "        if current_step <= num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        \n",
    "        # after warm up\n",
    "        progress = float(current_step - num_warmup_steps) / float(\n",
    "            max(1, num_training_steps - num_warmup_steps)\n",
    "        )\n",
    "        return max(\n",
    "            0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "        )\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de344f8",
   "metadata": {},
   "source": [
    "## Train&Validate process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78c1e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model forward function\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "    model.train()\n",
    "    mels, labels = batch\n",
    "    mels = mels.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    out = model(mels)\n",
    "    \n",
    "    loss = criterion(out, labels)\n",
    "    \n",
    "    pred = out.argmax(dim = 1)\n",
    "    accuracy = torch.mean((pred == labels).float())\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def valid(dataloader, model, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    loss_seq = []\n",
    "    accuracy_seq = []\n",
    "    bar = tqdm(dataloader, desc = 'Valid')\n",
    "    \n",
    "    for mels, labels in bar:\n",
    "        mels = mels.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(mels)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        preds = outputs.argmax(dim = 1)\n",
    "        \n",
    "        accuracy = torch.mean((preds == labels).float())\n",
    "        bar.set_postfix(loss = loss.item(), accuracy = accuracy.item())\n",
    "        loss_seq.append(loss.item())\n",
    "        accuracy_seq.append(accuracy.item())\n",
    "    bar.close()    \n",
    "    model.train()\n",
    "    return np.mean(loss_seq), np.mean(accuracy_seq)\n",
    "    \n",
    "\n",
    "\n",
    "def train(config):\n",
    "    \n",
    "    data_dir = config['data_dir']\n",
    "    save_path = config['save_path']\n",
    "    batch_size = config['batch_size']\n",
    "    warmup_steps = config['warmup_steps']\n",
    "    valid_steps = config['valid_steps']\n",
    "    train_steps = config['train_steps']\n",
    "    early_stops = config['early_stops']\n",
    "    model_type = config['model_type']\n",
    "    \n",
    "    # set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'[Info]: {device} is used')\n",
    "    \n",
    "    # load data\n",
    "    trainloader, validloader, speaker_num = get_dataloader(data_dir, batch_size)\n",
    "    \n",
    "    # creating model\n",
    "    if model_type == 'classic':\n",
    "        model = Classifier(n_spks = speaker_num).to(device)\n",
    "    elif model_type == 'conformer':\n",
    "        model = ConformerEncoder(n_spks=speaker_num).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    lr_scheduler = lr_schedule_with_warmup(optimizer,warmup_steps, train_steps)\n",
    "    \n",
    "    best_accuracy = -1\n",
    "    early_step = 0\n",
    "    \n",
    "    for e in range(train_steps):\n",
    "        \n",
    "        train_bar = tqdm(trainloader)\n",
    "        train_bar.set_description(f'Epoch: {e}/{train_steps}')\n",
    "        for batch in train_bar:\n",
    "            loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            train_bar.set_postfix(loss = loss.item(), accuracy = accuracy.item())\n",
    "            \n",
    "    \n",
    "        if (e + 1)%valid_steps == 0:\n",
    "            valid_loss, valid_accuracy = valid(validloader, model, criterion, device)\n",
    "        \n",
    "            if valid_accuracy > best_accuracy:\n",
    "                best_accuracy = valid_accuracy\n",
    "                best_state_dict = model.state_dict()\n",
    "                torch.save(best_state_dict, os.path.join(save_path, f'{model_type}_{e}.pth'))\n",
    "                print('The best model is saved')\n",
    "                early_step = 0\n",
    "            else:\n",
    "                early_step += 1\n",
    "    \n",
    "        if early_step > early_stops:\n",
    "            print(\"The model didn't improve, so we decide to shut down it\")\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a60aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_dir\": \"D://Datasets/Dataset/Dataset/\",\n",
    "    \"save_path\": \"D:\\Dropbox\\Deep learning\\Deep Learning Hongyi Li\\\\4\\save_models\",\n",
    "    \"batch_size\": 32,\n",
    "    \"valid_steps\": 2,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"save_steps\": 10000,\n",
    "    \"train_steps\": 70000,\n",
    "    'early_stops':5,\n",
    "    'model_type':'conformer'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c91de",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6e7e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "## Inference dataset\n",
    "class Inferencedataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        testdata_path = os.path.join(data_dir, 'testdata.json')\n",
    "        self.data = json.load(open(testdata_path))['utterances']\n",
    "        self.data_dir = data_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        utterance = self.data[idx]\n",
    "        feat_path = utterance['feature_path']\n",
    "        mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "        return feat_path, mel\n",
    "\n",
    "def inference_collate_bath(batch):\n",
    "    feat_pathes, mel = list(zip(*batch))\n",
    "    return feat_pathes, torch.stack(mel)\n",
    "\n",
    "def Inference(config):\n",
    "    \n",
    "    data_dir = config['data_dir']\n",
    "    model_path = config['model_path']\n",
    "    output_path = config['output_path']\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    mapping = json.load(open(os.path.join(data_dir, 'mapping.json')))\n",
    "    \n",
    "    dataset = Inferencedataset(data_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, drop_last=False,\n",
    "                            collate_fn=inference_collate_bath)\n",
    "    \n",
    "    speaker_num = len(mapping['id2speaker'])\n",
    "    \n",
    "    model = Classifier(n_spks=speaker_num).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    results = [['Id', 'Category']]\n",
    "    for feat_path, mel in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            mel = mel.to(device)\n",
    "            out = model(mel)\n",
    "            pred = out.argmax(dim = 1).cpu().numpy()\n",
    "            for f, p in zip(feat_path, pred):\n",
    "                results.append([f, mapping[\"id2speaker\"][str(pred[0])]])\n",
    "        \n",
    "    with open(output_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ad8535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_inf = {\n",
    "    'data_dir': \"D://Datasets/Dataset/Dataset/\",\n",
    "    'model_path': 'D:\\Dropbox\\Deep learning\\Deep Learning Hongyi Li\\\\4\\save_models\\model_51.pth',\n",
    "    'output_path': 'D:\\Dropbox\\Deep learning\\Deep Learning Hongyi Li\\\\4\\prediction.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be99fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:14<00:00, 559.24it/s]\n"
     ]
    }
   ],
   "source": [
    "Inference(config_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf3b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Mydataset(config['data_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba9ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 108, 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
